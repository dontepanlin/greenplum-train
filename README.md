# Greenplum train

Тестовый стенд для оттачивания навыков администрирования Greenplum

## Для работы требуются:

* `docker`
* `just`

## Команды just:

Команды нужны для удобства.

* `just build` - собирает базовый образ `greenplum`
* `just start` - запускает сервера кластера(вызывает `docker compose up`)
* `just stop` - останавливает сервера кластера(вызывает `docker compose down`)
* `just start` - перезапуск серверов кластера
* `just clean-ssh` - очищает ssh конфигурации для всех серверов
* `just clean-data` - очищает данные greenplum со всех узлов
* `just kill-master` - убить мастер сервер
* `just kill-primary target` - убить сервер по имени. Предполагается использовать для выключения узлов с данными
* `just start target` - запуск определенного узла

## Подключение к узлам

* `docker compose exec -it coordinator bash`
* `docker compose exec -it standby bash`

## Создание кластера

Команды выполняются на мастере

1. `bash /init_master.ssh` - устанавливает ssh без пароля между всеми узлами greenplum
2. `gpinitsystem -c ./gpinitsystem_config -h hostfile_gpinitsystem -s standby` - можно убрать параметр standby.
3. Проверить запущенный кластер: `gpstate`

## Сценарий потери мастера
Мастер упал, необходимо экстренно заменить его на standby сервер. 

1. Создать кластер
2. Убить мастер сервер
3. Подключится к standby
4. `gpactivatestandby` - соглашаемся, дожидаемся востановления
5. Проверить работу кластера: `gpstate`
6. Выполнить `psql postgres -c 'ANALYZE;`, для обновления статистики по запросам
7. Запустить "упавший" мастер, якобы его удалось восстановить.
8. Остановить standby: `gpstop -m`. Параметр -m останавливает только мастер
9. Синхронизация с мастером: `gpactivatestandby -d $MASTER_DATA_DIRECTORY`
10. Подключится к мастеру
11. Запустить кластер `gpstart`
12. Переназначить standby: `gpinitstandby -s standby`

> Можно автоматизировать процесс активации standby, путем наличия probe состояния с последующей реакцией на потерю связи.

## Сценарий потери узла данных
Один из узел с данным упал, необходимо восстановить сегменты данных из зеркал.

1. Создать кластер
2. Убить один из серверов с данными
3. Подключиться к мастеру
4. Оценить состояние кластера: `gpstate`. 
5. Greenplum автоматически переключается на mirror сегменты при сбое primary сегментов, если конфигурация репликации правильно настроена.
6. Однако, если этого не произошло автоматически, администратор может вручную переключить сегмент на его зеркальный сегмент `gprecoverseg -a -F`. Параметр -F (forced) используется для принудительного восстановления на зеркальные сегменты, даже если система работает в деградированном состоянии.
7. После запустить "упавший" узел данных, якобы его удалось восстановить.
8. Проверить что некоторые узлы не работают как положен. Выступают в роли primary для не своих сегментов: `gpstate -e`
9. По необходимость сбалансировать сегменты: `gprecoverseg -r`