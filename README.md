# Greenplum train

Тестовый стенд для оттачивания навыков администрирования Greenplum

## Для работы требуются:

* `docker`
* `just`

## Команды just:

Команды нужны для удобства.

* `just build` - собирает базовый образ `greenplum`
* `just start` - запускает сервера кластера(вызывает `docker compose up`)
* `just stop` - останавливает сервера кластера(вызывает `docker compose down`)
* `just restart` - перезапуск серверов кластера (down, up).
* `just shell <target>` - открыть shell на заданном узле
* `just clean-ssh` - очищает ssh конфигурации для всех серверов. Команду можно выполнить если необходимо обновить ssh конфигурации.
* `just clean-data` - очищает данные greenplum со всех узлов. Стоит выполнять эту команду когда необходимо создать новый кластер. 
* `just kill-master` - убить мастер сервер
* `just kill <target>` - убить сервер по имени. Предполагается использовать для выключения узлов с данными
* `just start-one <target>` - запуск определенного узла
* ``

## Подключение к узлам

* `docker compose exec -it coordinator bash`
* `docker compose exec -it standby bash`

## Создание кластера

Команды выполняются на мастере

1. `bash /init_master.sh` - устанавливает ssh без пароля между всеми узлами greenplum
2. `gpinitsystem -c ./gpinitsystem_config -h hostfile_gpinitsystem -s standby` - можно убрать параметр standby.
3. Проверить запущенный кластер: `gpstate`

## Сценарий потери мастера
Мастер упал, необходимо экстренно заменить его на standby сервер. 

1. Создать кластер
2. Убить мастер сервер
3. Подключится к standby
4. `gpactivatestandby` - соглашаемся, дожидаемся востановления
5. Проверить работу кластера: `gpstate`
6. Выполнить `psql postgres -c 'ANALYZE;'`, для обновления статистики по запросам
7. После этого standby становится новым мастером.
8. Разработчики greenplum рекомендуют дальше только добавить новый standby
9. Можно попытаться восстановить все как было, для этого можно выполнить `gpstart -m`, на поднятом мастер узле. Однако нигде не указаны гарантии автоматической синхронизации журналов между standby и мастером.

> Можно автоматизировать процесс активации standby, путем наличия probe состояния с последующей реакцией на потерю связи.

## Сценарий потери узла данных
Один из узел с данным упал, необходимо восстановить сегменты данных из зеркал.

1. Создать кластер
2. Убить один из серверов с данными
3. Подключиться к мастеру
4. Оценить состояние кластера: `gpstate`. 
5. Greenplum автоматически переключается на mirror сегменты при сбое primary сегментов, если конфигурация репликации правильно настроена.
6. Однако, если этого не произошло автоматически, администратор может вручную переключить сегмент на его зеркальный сегмент `gprecoverseg -a -F`. Параметр -F (forced) используется для принудительного восстановления на зеркальные сегменты, даже если система работает в деградированном состоянии.
7. После запустить "упавший" узел данных, якобы его удалось восстановить.
8. Проверить что некоторые узлы не работают как положен. Выступают в роли primary для не своих сегментов: `gpstate -e`
9. По необходимость сбалансировать сегменты: `gprecoverseg -r`
